# -*- coding: utf-8 -*-
"""test&plotCNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Cvcd35AtdqqeJQbEFzJQKJIZqYgO2S7g
"""

#Loss and Accuracy History
def plot_accuracies(history):
    accuracies = [x['train_acc'] for x in history[1:]] # Skip the first element
    val_accuracies = [x['val_acc'] for x in history[1:]] # Skip the first element
    plt.plot(accuracies, '-x')
    plt.plot(val_accuracies, '-o')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend(['Training', 'Validation'])
    plt.title('Accuracy over epochs')
    plt.grid(True)
    plt.show()

def plot_losses(history):
    train_losses = [x['train_loss'] for x in history[1:]] # Skip the first element
    val_losses = [x['val_loss'] for x in history[1:]] # Skip the first element
    plt.plot(train_losses, '-x')
    plt.plot(val_losses, '-o')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend(['Training', 'Validation'])
    plt.title('Loss over epochs')
    plt.grid(True)
    plt.show()

plot_accuracies(history)
plot_losses(history)

# test_ds define Dataloader from the test dataset you have already allocated
test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE*2, num_workers=2, pin_memory=True)
test_dl = DeviceDataLoader(test_dl, device)

test_result = evaluate(flower_cnn, test_dl)
print("Test Accuracy: {:.2f}%".format(test_result['val_acc'] * 100))

from sklearn.metrics import classification_report, confusion_matrix
import numpy as np

#This function takes predictions from test data and returns them with the actual labels.
def get_all_preds(model, loader):
    model.eval()
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for images, labels in loader:
            images = images.to(device)
            labels = labels.to(device)
            outputs = model(images)
            _, preds = torch.max(outputs, dim=1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    return np.array(all_preds), np.array(all_labels)

#Get predictions
preds, labels = get_all_preds(flower_cnn, test_dl)

#Performance report
print("Classification Report:\n")
print(classification_report(labels, preds, target_names=original_dataset.classes))

import seaborn as sns
import matplotlib.pyplot as plt

#confusion matrix visualization
cm = confusion_matrix(labels, preds)
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=original_dataset.classes, yticklabels=original_dataset.classes, cmap="Blues") # Use original_dataset.classes
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()