# -*- coding: utf-8 -*-
"""dataloaderVGG16FineTun.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HQXgZ5orQT4CSwQSGKKQDRukkXzTjo4T
"""

# Import necessary libraries
import os
import opendatasets as od
import tensorflow as tf
from tensorflow.keras import models,applications,layers,losses,callbacks
from sklearn.metrics import confusion_matrix,classification_report
import numpy as np
import seaborn as sn
import pathlib
import PIL
import cv2
from sklearn.model_selection import train_test_split
from matplotlib import pyplot as plt
import cv2
import numpy as np
from pathlib import Path
from google.colab.patches import cv2_imshow # Import cv2_imshow

#Defining the dataset URL
dataset_url = "https://www.kaggle.com/datasets/alxmamaev/flowers-recognition?datasetId=8782&sortBy=voteCount"

#Defining the data directory
data_dir = './flowers-recognition/flowers'

#If there is no folder, download the dataset
if not os.path.isdir(data_dir):
    od.download(dataset_url)

#List classes
classes = os.listdir(data_dir)
print(classes)

#Define the data directory (custom structure for Kaggle)
data_dir = Path("./flowers-recognition/flowers")

#Collecting images of each flower type in the dictionary
flowers_img_dict = {
    'rose': list((data_dir/'rose').glob('*.jpg')),
    'daisy': list((data_dir/'daisy').glob('*.jpg')),
    'dandelion': list((data_dir/'dandelion').glob('*.jpg')),
    'sunflower': list((data_dir/'sunflower').glob('*.jpg')),
    'tulip': list((data_dir/'tulip').glob('*.jpg')),
}

#Assigning numerical labels to each flower type
flowers_lbl_dict = {
    'daisy': 0,
    'dandelion': 1,
    'rose': 2,
    'sunflower': 3,
    'tulip': 4
}


#Read and show the first rose image
if len(flowers_img_dict['rose']) > 0:
    img = cv2.imread(str(flowers_img_dict['rose'][0]))

    #Print image information
    print('Numpy array shape:', img.shape)
    print('Data type:', img.dtype)
    print('Min/Max values:', np.min(img), np.max(img))

    #Show image
    cv2_imshow(img)

else:
    print("No rose images found!")
    print("Current directory structure:", [p.name for p in data_dir.iterdir() if p.is_dir()])

# Reading an image as numpy array
img=cv2.imread(str(flowers_img_dict['rose'][0]))
print('numpy array of an image:\n',img)

# check number of images in each type of flowers
for fldr_name,images in flowers_img_dict.items():
  print(fldr_name)
  print(len(images))

#Creates the input (X) and label (Y) dataset from flower images and resizes each image to the same size (100x100 pixels)
#The model is brought to the required format for training.
X,Y=[],[]
for flowr_name,images in flowers_img_dict.items():
  for image in images:
    img=cv2.imread(str(image))
    resized_img=cv2.resize(img,(224,224))
    X.append(resized_img)
    Y.append(flowers_lbl_dict[flowr_name])

#Converting lists to NumPy arrays
X=np.array(X)
Y=np.array(Y)
print('X:\n',X)
print('Y\n',Y)

#divides the image and label data you create into training (train) and test (test) sets.
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,random_state=0)
print('size of X_train:',X_train.shape) # check size of X_train
print('size of X_test:',X_test.shape) # check size of X_test
print('size of Y_train:',Y_train.shape) # check size of Y_train
print('size of Y_test:',Y_test.shape) # check size of Y_test

# Normalize the pixel values to the range [0, 1]
X_train=X_train/255
X_test=X_test/255

# Data augmentation to enhance model robustness
data_aug=tf.keras.Sequential([
    layers.RandomZoom(0.3),   #Zoom in or out of the image up to 30%
    layers.RandomFlip("horizontal_and_vertical"),   #Horizontal and vertical random flip
    layers.RandomRotation(0.2),   #Randomly rotate the image within ±20°
])